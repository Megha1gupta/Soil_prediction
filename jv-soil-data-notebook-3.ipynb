{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":102672,"databundleVersionId":12375409,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from collections import Counter\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import DataLoader, Dataset\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport pandas as pd\nfrom PIL import Image # Needed for handling images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:19:34.996137Z","iopub.execute_input":"2025-05-24T11:19:34.996738Z","iopub.status.idle":"2025-05-24T11:19:45.024166Z","shell.execute_reply.started":"2025-05-24T11:19:34.996679Z","shell.execute_reply":"2025-05-24T11:19:45.023259Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:19:57.321337Z","iopub.execute_input":"2025-05-24T11:19:57.322126Z","iopub.status.idle":"2025-05-24T11:19:57.373660Z","shell.execute_reply.started":"2025-05-24T11:19:57.322104Z","shell.execute_reply":"2025-05-24T11:19:57.373028Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 1. Data Preparation and Augmentation\n# =====================================\n\n# Define data transformations for training, validation, and testing\n# Training data augmentation is crucial for improving model generalization\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),  # Randomly crop and resize to 224x224\n        transforms.RandomHorizontalFlip(),  # Randomly flip horizontally\n        transforms.ToTensor(),             # Convert to PyTorch tensor\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize with ImageNet statistics\n    ]),\n    'test': transforms.Compose([ # Added test transforms.  Important to have consistent preprocessing.\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:20:26.428186Z","iopub.execute_input":"2025-05-24T11:20:26.428451Z","iopub.status.idle":"2025-05-24T11:20:26.433364Z","shell.execute_reply.started":"2025-05-24T11:20:26.428431Z","shell.execute_reply":"2025-05-24T11:20:26.432587Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class SoilDataset(Dataset):\n    \"\"\"\n    A custom dataset class for loading soil images and labels from a separate file.\n    \"\"\"\n    def __init__(self, data_dir, label_file, transform=None, phase='train', classes=None,\n                class_to_idx=None):\n        \"\"\"\n        Args:\n            data_dir (str): Path to the directory containing the images.\n            label_file (str): Path to the CSV file containing the labels.\n            transform (callable, optional): Optional transform to be applied on a sample.\n            phase (str):  'train', 'val', or 'test' to indicate the subset to load.\n        \"\"\"\n        self.data_dir = data_dir\n        self.label_file = label_file\n        self.transform = transform\n        self.phase = phase\n        \n        # Filter the dataframe based on the phase.  Assume label_file has a 'split' column.\n\n        if phase == 'train':\n            self.labels_df = pd.read_csv(label_file)\n            self.image_names = self.labels_df['image_id'].tolist() # get the image file names\n            self.labels = self.labels_df['soil_type'].tolist() # get the labels\n            self.classes = sorted(list(set(self.labels)))  # Get unique class names\n            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)} # create a mapping\n        else:\n            self.image_names = [f for f in os.listdir(f\"{data_dir}/{phase}\") if os.path.isfile(os.path.join(f\"{data_dir}/{phase}\", f))]\n            self.labels = ['Alluvial soil'] * len(self.image_names) # dummy labels\n            self.classes = classes\n            self.class_to_idx = class_to_idx\n    def __len__(self):\n        return len(self.image_names)\n\n    def __getitem__(self, idx):\n        img_name = self.image_names[idx]\n        img_path = os.path.join(f\"{self.data_dir}/{self.phase}\", img_name) # full path.\n        image = Image.open(img_path).convert('RGB')  # Load the image\n\n        label = self.labels[idx]\n        label_idx = self.class_to_idx[label] # convert label name to index.\n\n        if self.transform:\n            image = self.transform(image)\n        if self.phase == \"test\":\n            label_idx = img_name\n            \n\n        return image, label_idx\n\n\n\ndata_dir = '/kaggle/input/soil-classification/soil_classification-2025/'  # Replace with the path to your image data directory\nlabel_file = '/kaggle/input/soil-classification/soil_classification-2025/train_labels.csv'  # Replace with the path to your CSV label file\nimage_datasets = {\n    'train': SoilDataset(data_dir, label_file, transform=data_transforms['train'], phase='train')}\n\nimage_datasets['test']=SoilDataset(data_dir, None, transform=data_transforms['train'], phase='test',\n                                  classes=image_datasets['train'].classes,\n                                  class_to_idx=image_datasets['train'].class_to_idx,)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:20:36.987740Z","iopub.execute_input":"2025-05-24T11:20:36.988497Z","iopub.status.idle":"2025-05-24T11:20:37.845354Z","shell.execute_reply.started":"2025-05-24T11:20:36.988465Z","shell.execute_reply":"2025-05-24T11:20:37.844589Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Create data loaders\n#  -  These handle batching, shuffling, and parallel data loading\ndataloaders = {\n    'train': DataLoader(image_datasets['train'], batch_size=8, shuffle=True, num_workers=4),\n    'test': DataLoader(image_datasets['test'], batch_size=8, shuffle=False, num_workers=4) # Create test dataloader\n}\n\n# Get the class names.  This is important for mapping predictions to soil types.\nclass_names = image_datasets['train'].classes\nnum_classes = len(class_names) # number of classes\n\nprint(f\"Number of classes: {num_classes}\")\nprint(f\"Classes: {class_names}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:20:44.783141Z","iopub.execute_input":"2025-05-24T11:20:44.783616Z","iopub.status.idle":"2025-05-24T11:20:44.788662Z","shell.execute_reply.started":"2025-05-24T11:20:44.783593Z","shell.execute_reply":"2025-05-24T11:20:44.787959Z"}},"outputs":[{"name":"stdout","text":"Number of classes: 4\nClasses: ['Alluvial soil', 'Black Soil', 'Clay soil', 'Red soil']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# 7. Save the Model (Optional)\n# ============================\ndef save_model(model, path='soil_classification_model.pth'):\n    \"\"\"Saves the trained model to a specified path.\n\n    Args:\n        model (torch.nn.Module): The trained model.\n        path (str, optional): The path to save the model.\n            Defaults to 'soil_classification_model.pth'.\n    \"\"\"\n    torch.save(model.state_dict(), path)\n    print(f'Model saved to {path}')\n\n# Save the model\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:20:52.737378Z","iopub.execute_input":"2025-05-24T11:20:52.737941Z","iopub.status.idle":"2025-05-24T11:20:52.741437Z","shell.execute_reply.started":"2025-05-24T11:20:52.737918Z","shell.execute_reply":"2025-05-24T11:20:52.740825Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# 2. Model Definition ( with Fine-tuning)\n# ==============================================\ndef create_efficient_net_model(num_classes, fine_tune=True):\n    \"\"\"\n    Loads a pre-trained _efficient_net_ model and modifies the final fully connected layer\n    for the specific number of classes in the soil classification task.  Optionally\n    freezes the earlier layers.\n\n    Args:\n        num_classes (int): The number of soil classes.\n        fine_tune (bool, optional): If True, fine-tunes the entire model.\n            If False, freezes the base layers and only trains the classifier.\n            Defaults to True.\n\n    Returns:\n        torch.nn.Module: The modified _efficient_net_ model.\n    \"\"\"\n    model_ft = models.efficientnet_b0(weights='IMAGENET1K_V1') #(weights=models.ResNet50_Weights.IMAGENET1K_V1) # Use the pretrained weights\n\n    # Get the number of input features for the final fully connected layer\n    in_features = model_ft.classifier[1].in_features\n\n    # Replace the final fully connected layer with a new one\n    # that has the number of output features equal to the number of classes.\n    model_ft.classifier[1] = nn.Linear(in_features, num_classes)\n\n    if not fine_tune:\n        # Freeze all the parameters in the network\n        for param in model_ft.parameters():\n            param.requires_grad = False\n    model_ft.classifier[1].requires_grad = True\n\n    return model_ft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:21:12.102157Z","iopub.execute_input":"2025-05-24T11:21:12.103044Z","iopub.status.idle":"2025-05-24T11:21:12.107694Z","shell.execute_reply.started":"2025-05-24T11:21:12.103012Z","shell.execute_reply":"2025-05-24T11:21:12.107047Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def create_efficient_net_b1_model(num_classes, fine_tune=True):\n    \"\"\"\n    Loads a pre-trained model and modifies the final fully connected layer.\n\n    Args:\n        num_classes (int): The number of output classes.\n        fine_tune (bool): If True, all layers are trainable. If False, base layers are frozen.\n\n    Returns:\n        torch.nn.Module: The modified model.\n    \"\"\"\n    model_ft = models.efficientnet_b2(weights='IMAGENET1K_V1')\n\n    if not fine_tune:\n        # Freeze all parameters in the feature extractor (base layers)\n        for param in model_ft.parameters():\n            param.requires_grad = False\n        # Unfreeze the final classification layer if it was frozen by the above loop\n        model_ft.classifier[1].requires_grad = True # Ensure the new FC layer is trainable\n\n    # Get the number of input features for the final fully connected layer\n    in_features = model_ft.classifier[1].in_features\n    \n    # Replace the final fully connected layer with a new one for `num_classes`\n    model_ft.classifier[1] = nn.Linear(in_features, num_classes)\n\n    return model_ft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:21:32.574860Z","iopub.execute_input":"2025-05-24T11:21:32.575317Z","iopub.status.idle":"2025-05-24T11:21:32.579485Z","shell.execute_reply.started":"2025-05-24T11:21:32.575295Z","shell.execute_reply":"2025-05-24T11:21:32.578750Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Create the model\nefficient_net_model_ft = create_efficient_net_model(num_classes, fine_tune=True) # Set fine_tune to True to train the whole network\nefficient_net_model_ft = efficient_net_model_ft.to(device)  # Move the model to the GPU if available\n\nefficient_net_model_base = create_efficient_net_model(num_classes, fine_tune=True) # Set fine_tune to True to train the whole network\nefficient_net_model_base = efficient_net_model_base.to(device)  # Move the model to the GPU if available\n\nv1_model_ft = create_efficient_net_b1_model(num_classes, fine_tune=True) # Set fine_tune to True to train the whole network\nv1_model_ft = v1_model_ft.to(device)  # Move the model to the GPU if available\n\nv1_model_base = create_efficient_net_b1_model(num_classes, fine_tune=False) # Set fine_tune to True to train the whole network\nv1_model_base = v1_model_base.to(device)  # Move the model to the GPU if available\n\n\n# 3. Loss Function and Optimizer\n# ==============================\n# Define the loss function (CrossEntropyLoss is suitable for multi-class classification)\ntrain_labels = torch.tensor([image_datasets[\"train\"].class_to_idx[t] for t in image_datasets[\"train\"].labels])\nclass_counts = torch.bincount(train_labels, minlength=num_classes).float()\ntotal_samples = class_counts.sum()\nweights_calculated = total_samples / (num_classes * class_counts)\nprint(f\"\\nCalculated Class Counts: {class_counts.tolist()}\")\nprint(f\"Calculated Class Weights: {weights_calculated.tolist()}\")\n\n#weights = 1/torch.tensor(counts_list, dtype=torch.float)\ncriterion_weighted = nn.CrossEntropyLoss(weight=weights_calculated.to(device))\ncriterion = nn.CrossEntropyLoss()\n\n# Define the optimizer.\n#  -  If fine_tune is False, only the parameters of the new fully connected layer will be updated.\n#  -  If fine_tune is True, all parameters will be updated.\noptimizer_efficient_ft = optim.AdamW(efficient_net_model_ft.parameters(), lr=0.001)\noptimizer_efficient_base = optim.AdamW(efficient_net_model_base.parameters(), lr=0.0001)\noptimizer_v1_ft = optim.AdamW(v1_model_ft.parameters(), lr=0.001)\noptimizer_v1_base = optim.AdamW(v1_model_base.parameters(), lr=0.0001)\n\n# Define a learning rate scheduler to decrease the learning rate over time\n# This can help the model converge better.\nexp_lr_scheduler_eff = lr_scheduler.StepLR(optimizer_efficient_ft, step_size=7, gamma=0.1)\nexp_lr_scheduler_base = lr_scheduler.StepLR(optimizer_efficient_base, step_size=7, gamma=0.1)\nexp_lr_scheduler_v1 = lr_scheduler.StepLR(optimizer_v1_ft, step_size=7, gamma=0.1)\nexp_lr_scheduler_v1_base = lr_scheduler.StepLR(optimizer_v1_base, step_size=7, gamma=0.1)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:21:36.994912Z","iopub.execute_input":"2025-05-24T11:21:36.995149Z","iopub.status.idle":"2025-05-24T11:21:38.286903Z","shell.execute_reply.started":"2025-05-24T11:21:36.995134Z","shell.execute_reply":"2025-05-24T11:21:38.286132Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n100%|██████████| 20.5M/20.5M [00:00<00:00, 192MB/s]\nDownloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-c35c1473.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b2_rwightman-c35c1473.pth\n100%|██████████| 35.2M/35.2M [00:00<00:00, 235MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\nCalculated Class Counts: [528.0, 231.0, 199.0, 264.0]\nCalculated Class Weights: [0.5785984992980957, 1.322510838508606, 1.5351759195327759, 1.1571969985961914]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# 4. Model Training and Validation\n# ==================================\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=50):\n    \"\"\"\n    Trains the model for a specified number of epochs, performing validation\n    at the end of each epoch.\n\n    Args:\n        model (torch.nn.Module): The model to train.\n        criterion (torch.nn.Module): The loss function.\n        optimizer (torch.optim.Optimizer): The optimizer.\n        scheduler (torch.optim.lr_scheduler._LRScheduler): The learning rate scheduler.\n        num_epochs (int, optional): The number of epochs to train for. Defaults to 25.\n\n    Returns:\n        torch.nn.Module: The trained model.\n    \"\"\"\n    best_acc = 0.0  # Initialize the best validation accuracy\n    # Store the loss and accuracy for each epoch\n    history = {\n        'train_loss': [],\n        'train_acc': [],\n        'val_loss': [],\n        'val_acc': []\n    }\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data in batches\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device) # Move the inputs to the device (GPU or CPU)\n                labels = labels.to(device) # Move the labels to the device\n\n                # Zero the parameter gradients\n                optimizer.zero_grad()\n\n                # Forward pass\n                # Track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs) # Get the model's output\n                    _, preds = torch.max(outputs, 1)  # Get the predicted class labels\n                    loss = criterion(outputs, labels) # Calculate the loss\n\n                    if phase == 'train':\n                        loss.backward()        # Backpropagate the loss\n                        optimizer.step()       # Update the model parameters\n\n                # Statistics\n                running_loss += loss.item() * inputs.size(0) # Accumulate the loss\n                running_corrects += torch.sum(preds == labels.data)  # Accumulate the number of correct predictions\n\n            # Calculate the loss and accuracy for this epoch\n            epoch_loss = running_loss / len(image_datasets[phase])\n            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n            history[f'{phase}_loss'].append(epoch_loss)\n            history[f'{phase}_acc'].append(epoch_acc.item())\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n            # Deep copy the model if it's the best one seen so far\n            if epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = model.state_dict() # save the weights\n                print(f'Best val Acc: {best_acc:.4f}')\n\n        if phase == 'train': # Step the scheduler *after* the epoch\n            scheduler.step()\n\n    print(f'Finished Training. Best val Acc: {best_acc:.4f}')\n    model.load_state_dict(best_model_wts) # load the weights of the best model\n    return model, history\n\n\n\n# Train the model\nnum_epochs = 35 # You can adjust the number of epochs\n\n# try:\n#     efficient_net_model_ft.load_state_dict(torch.load('soil_classification_model_efficient_net.pth', map_location=device))\n#     efficient_net_model_base.load_state_dict(torch.load('soil_classification_model_efficient_net_base.pth', map_location=device))\n#     resnet_model_ft.load_state_dict(torch.load('soil_classification_model_resnet.pth', map_location=device))\n#     resnet_model_base.load_state_dict(torch.load('soil_classification_model_resnet_base.pth', map_location=device))\n# except:\n#     pass\nefficient_net_model_ft, history = train_model(efficient_net_model_ft, criterion_weighted, optimizer_efficient_ft, exp_lr_scheduler_eff, num_epochs=num_epochs)\nv1_model_ft, history = train_model(v1_model_ft, criterion_weighted, optimizer_v1_ft, exp_lr_scheduler_v1, num_epochs=num_epochs)\nefficient_net_model_base, history = train_model(efficient_net_model_base, criterion_weighted, optimizer_efficient_base, exp_lr_scheduler_base, num_epochs=num_epochs)\nv1_model_base, history = train_model(v1_model_base, criterion_weighted, optimizer_v1_base, exp_lr_scheduler_v1_base, num_epochs=num_epochs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:21:42.685418Z","iopub.execute_input":"2025-05-24T11:21:42.685705Z","iopub.status.idle":"2025-05-24T11:41:20.352234Z","shell.execute_reply.started":"2025-05-24T11:21:42.685670Z","shell.execute_reply":"2025-05-24T11:41:20.351277Z"}},"outputs":[{"name":"stdout","text":"Epoch 0/34\n----------\ntrain Loss: 0.6952 Acc: 0.7406\nBest val Acc: 0.7406\nEpoch 1/34\n----------\ntrain Loss: 0.5859 Acc: 0.7856\nBest val Acc: 0.7856\nEpoch 2/34\n----------\ntrain Loss: 0.4869 Acc: 0.8093\nBest val Acc: 0.8093\nEpoch 3/34\n----------\ntrain Loss: 0.4183 Acc: 0.8429\nBest val Acc: 0.8429\nEpoch 4/34\n----------\ntrain Loss: 0.4171 Acc: 0.8470\nBest val Acc: 0.8470\nEpoch 5/34\n----------\ntrain Loss: 0.4365 Acc: 0.8404\nEpoch 6/34\n----------\ntrain Loss: 0.3767 Acc: 0.8560\nBest val Acc: 0.8560\nEpoch 7/34\n----------\ntrain Loss: 0.2140 Acc: 0.9075\nBest val Acc: 0.9075\nEpoch 8/34\n----------\ntrain Loss: 0.2171 Acc: 0.9083\nBest val Acc: 0.9083\nEpoch 9/34\n----------\ntrain Loss: 0.1922 Acc: 0.9239\nBest val Acc: 0.9239\nEpoch 10/34\n----------\ntrain Loss: 0.1903 Acc: 0.9247\nBest val Acc: 0.9247\nEpoch 11/34\n----------\ntrain Loss: 0.1658 Acc: 0.9313\nBest val Acc: 0.9313\nEpoch 12/34\n----------\ntrain Loss: 0.1369 Acc: 0.9525\nBest val Acc: 0.9525\nEpoch 13/34\n----------\ntrain Loss: 0.1702 Acc: 0.9354\nEpoch 14/34\n----------\ntrain Loss: 0.1233 Acc: 0.9476\nEpoch 15/34\n----------\ntrain Loss: 0.1252 Acc: 0.9525\nEpoch 16/34\n----------\ntrain Loss: 0.1278 Acc: 0.9444\nEpoch 17/34\n----------\ntrain Loss: 0.1184 Acc: 0.9542\nBest val Acc: 0.9542\nEpoch 18/34\n----------\ntrain Loss: 0.1327 Acc: 0.9501\nEpoch 19/34\n----------\ntrain Loss: 0.1194 Acc: 0.9574\nBest val Acc: 0.9574\nEpoch 20/34\n----------\ntrain Loss: 0.1138 Acc: 0.9509\nEpoch 21/34\n----------\ntrain Loss: 0.1250 Acc: 0.9468\nEpoch 22/34\n----------\ntrain Loss: 0.1351 Acc: 0.9476\nEpoch 23/34\n----------\ntrain Loss: 0.1141 Acc: 0.9525\nEpoch 24/34\n----------\ntrain Loss: 0.1288 Acc: 0.9534\nEpoch 25/34\n----------\ntrain Loss: 0.1065 Acc: 0.9574\nEpoch 26/34\n----------\ntrain Loss: 0.1148 Acc: 0.9534\nEpoch 27/34\n----------\ntrain Loss: 0.1177 Acc: 0.9542\nEpoch 28/34\n----------\ntrain Loss: 0.1144 Acc: 0.9574\nEpoch 29/34\n----------\ntrain Loss: 0.1637 Acc: 0.9476\nEpoch 30/34\n----------\ntrain Loss: 0.1480 Acc: 0.9427\nEpoch 31/34\n----------\ntrain Loss: 0.1205 Acc: 0.9542\nEpoch 32/34\n----------\ntrain Loss: 0.1194 Acc: 0.9534\nEpoch 33/34\n----------\ntrain Loss: 0.1251 Acc: 0.9493\nEpoch 34/34\n----------\ntrain Loss: 0.1165 Acc: 0.9566\nFinished Training. Best val Acc: 0.9574\nEpoch 0/34\n----------\ntrain Loss: 0.7192 Acc: 0.7300\nBest val Acc: 0.7300\nEpoch 1/34\n----------\ntrain Loss: 0.5380 Acc: 0.7889\nBest val Acc: 0.7889\nEpoch 2/34\n----------\ntrain Loss: 0.5011 Acc: 0.8110\nBest val Acc: 0.8110\nEpoch 3/34\n----------\ntrain Loss: 0.4341 Acc: 0.8306\nBest val Acc: 0.8306\nEpoch 4/34\n----------\ntrain Loss: 0.4188 Acc: 0.8445\nBest val Acc: 0.8445\nEpoch 5/34\n----------\ntrain Loss: 0.3577 Acc: 0.8527\nBest val Acc: 0.8527\nEpoch 6/34\n----------\ntrain Loss: 0.3317 Acc: 0.8789\nBest val Acc: 0.8789\nEpoch 7/34\n----------\ntrain Loss: 0.2709 Acc: 0.8879\nBest val Acc: 0.8879\nEpoch 8/34\n----------\ntrain Loss: 0.1966 Acc: 0.9264\nBest val Acc: 0.9264\nEpoch 9/34\n----------\ntrain Loss: 0.1790 Acc: 0.9329\nBest val Acc: 0.9329\nEpoch 10/34\n----------\ntrain Loss: 0.1518 Acc: 0.9378\nBest val Acc: 0.9378\nEpoch 11/34\n----------\ntrain Loss: 0.1495 Acc: 0.9362\nEpoch 12/34\n----------\ntrain Loss: 0.1773 Acc: 0.9403\nBest val Acc: 0.9403\nEpoch 13/34\n----------\ntrain Loss: 0.1177 Acc: 0.9509\nBest val Acc: 0.9509\nEpoch 14/34\n----------\ntrain Loss: 0.1206 Acc: 0.9550\nBest val Acc: 0.9550\nEpoch 15/34\n----------\ntrain Loss: 0.1260 Acc: 0.9501\nEpoch 16/34\n----------\ntrain Loss: 0.1229 Acc: 0.9509\nEpoch 17/34\n----------\ntrain Loss: 0.1267 Acc: 0.9550\nEpoch 18/34\n----------\ntrain Loss: 0.1318 Acc: 0.9444\nEpoch 19/34\n----------\ntrain Loss: 0.1250 Acc: 0.9435\nEpoch 20/34\n----------\ntrain Loss: 0.1293 Acc: 0.9517\nEpoch 21/34\n----------\ntrain Loss: 0.1188 Acc: 0.9591\nBest val Acc: 0.9591\nEpoch 22/34\n----------\ntrain Loss: 0.1190 Acc: 0.9476\nEpoch 23/34\n----------\ntrain Loss: 0.1198 Acc: 0.9542\nEpoch 24/34\n----------\ntrain Loss: 0.1112 Acc: 0.9591\nEpoch 25/34\n----------\ntrain Loss: 0.1191 Acc: 0.9525\nEpoch 26/34\n----------\ntrain Loss: 0.1115 Acc: 0.9599\nBest val Acc: 0.9599\nEpoch 27/34\n----------\ntrain Loss: 0.1011 Acc: 0.9640\nBest val Acc: 0.9640\nEpoch 28/34\n----------\ntrain Loss: 0.1043 Acc: 0.9632\nEpoch 29/34\n----------\ntrain Loss: 0.1122 Acc: 0.9550\nEpoch 30/34\n----------\ntrain Loss: 0.1019 Acc: 0.9583\nEpoch 31/34\n----------\ntrain Loss: 0.1153 Acc: 0.9615\nEpoch 32/34\n----------\ntrain Loss: 0.1190 Acc: 0.9566\nEpoch 33/34\n----------\ntrain Loss: 0.0939 Acc: 0.9681\nBest val Acc: 0.9681\nEpoch 34/34\n----------\ntrain Loss: 0.1328 Acc: 0.9517\nFinished Training. Best val Acc: 0.9681\nEpoch 0/34\n----------\ntrain Loss: 0.7377 Acc: 0.7512\nBest val Acc: 0.7512\nEpoch 1/34\n----------\ntrain Loss: 0.4549 Acc: 0.8421\nBest val Acc: 0.8421\nEpoch 2/34\n----------\ntrain Loss: 0.3510 Acc: 0.8682\nBest val Acc: 0.8682\nEpoch 3/34\n----------\ntrain Loss: 0.3042 Acc: 0.8887\nBest val Acc: 0.8887\nEpoch 4/34\n----------\ntrain Loss: 0.2571 Acc: 0.9116\nBest val Acc: 0.9116\nEpoch 5/34\n----------\ntrain Loss: 0.2265 Acc: 0.9133\nBest val Acc: 0.9133\nEpoch 6/34\n----------\ntrain Loss: 0.2066 Acc: 0.9255\nBest val Acc: 0.9255\nEpoch 7/34\n----------\ntrain Loss: 0.1730 Acc: 0.9321\nBest val Acc: 0.9321\nEpoch 8/34\n----------\ntrain Loss: 0.1486 Acc: 0.9484\nBest val Acc: 0.9484\nEpoch 9/34\n----------\ntrain Loss: 0.1723 Acc: 0.9386\nEpoch 10/34\n----------\ntrain Loss: 0.1370 Acc: 0.9574\nBest val Acc: 0.9574\nEpoch 11/34\n----------\ntrain Loss: 0.1524 Acc: 0.9411\nEpoch 12/34\n----------\ntrain Loss: 0.1439 Acc: 0.9542\nEpoch 13/34\n----------\ntrain Loss: 0.1403 Acc: 0.9574\nEpoch 14/34\n----------\ntrain Loss: 0.1298 Acc: 0.9624\nBest val Acc: 0.9624\nEpoch 15/34\n----------\ntrain Loss: 0.1424 Acc: 0.9517\nEpoch 16/34\n----------\ntrain Loss: 0.1498 Acc: 0.9444\nEpoch 17/34\n----------\ntrain Loss: 0.1248 Acc: 0.9550\nEpoch 18/34\n----------\ntrain Loss: 0.1478 Acc: 0.9468\nEpoch 19/34\n----------\ntrain Loss: 0.1283 Acc: 0.9525\nEpoch 20/34\n----------\ntrain Loss: 0.1374 Acc: 0.9599\nEpoch 21/34\n----------\ntrain Loss: 0.1353 Acc: 0.9542\nEpoch 22/34\n----------\ntrain Loss: 0.1597 Acc: 0.9460\nEpoch 23/34\n----------\ntrain Loss: 0.1145 Acc: 0.9615\nEpoch 24/34\n----------\ntrain Loss: 0.1386 Acc: 0.9517\nEpoch 25/34\n----------\ntrain Loss: 0.1333 Acc: 0.9525\nEpoch 26/34\n----------\ntrain Loss: 0.1453 Acc: 0.9525\nEpoch 27/34\n----------\ntrain Loss: 0.1423 Acc: 0.9566\nEpoch 28/34\n----------\ntrain Loss: 0.1318 Acc: 0.9517\nEpoch 29/34\n----------\ntrain Loss: 0.1421 Acc: 0.9542\nEpoch 30/34\n----------\ntrain Loss: 0.1198 Acc: 0.9607\nEpoch 31/34\n----------\ntrain Loss: 0.1213 Acc: 0.9542\nEpoch 32/34\n----------\ntrain Loss: 0.1538 Acc: 0.9542\nEpoch 33/34\n----------\ntrain Loss: 0.1149 Acc: 0.9632\nBest val Acc: 0.9632\nEpoch 34/34\n----------\ntrain Loss: 0.1482 Acc: 0.9460\nFinished Training. Best val Acc: 0.9632\nEpoch 0/34\n----------\ntrain Loss: 1.2914 Acc: 0.4730\nBest val Acc: 0.4730\nEpoch 1/34\n----------\ntrain Loss: 1.0754 Acc: 0.7054\nBest val Acc: 0.7054\nEpoch 2/34\n----------\ntrain Loss: 0.9245 Acc: 0.7651\nBest val Acc: 0.7651\nEpoch 3/34\n----------\ntrain Loss: 0.8393 Acc: 0.7823\nBest val Acc: 0.7823\nEpoch 4/34\n----------\ntrain Loss: 0.7285 Acc: 0.7995\nBest val Acc: 0.7995\nEpoch 5/34\n----------\ntrain Loss: 0.7219 Acc: 0.7930\nEpoch 6/34\n----------\ntrain Loss: 0.6795 Acc: 0.8061\nBest val Acc: 0.8061\nEpoch 7/34\n----------\ntrain Loss: 0.6546 Acc: 0.8011\nEpoch 8/34\n----------\ntrain Loss: 0.6398 Acc: 0.8142\nBest val Acc: 0.8142\nEpoch 9/34\n----------\ntrain Loss: 0.6271 Acc: 0.8175\nBest val Acc: 0.8175\nEpoch 10/34\n----------\ntrain Loss: 0.6414 Acc: 0.8003\nEpoch 11/34\n----------\ntrain Loss: 0.6314 Acc: 0.8101\nEpoch 12/34\n----------\ntrain Loss: 0.6154 Acc: 0.8151\nEpoch 13/34\n----------\ntrain Loss: 0.6513 Acc: 0.7913\nEpoch 14/34\n----------\ntrain Loss: 0.6345 Acc: 0.8061\nEpoch 15/34\n----------\ntrain Loss: 0.6273 Acc: 0.8036\nEpoch 16/34\n----------\ntrain Loss: 0.6330 Acc: 0.8191\nBest val Acc: 0.8191\nEpoch 17/34\n----------\ntrain Loss: 0.6508 Acc: 0.7913\nEpoch 18/34\n----------\ntrain Loss: 0.6248 Acc: 0.8069\nEpoch 19/34\n----------\ntrain Loss: 0.6327 Acc: 0.8052\nEpoch 20/34\n----------\ntrain Loss: 0.6174 Acc: 0.8061\nEpoch 21/34\n----------\ntrain Loss: 0.6210 Acc: 0.7971\nEpoch 22/34\n----------\ntrain Loss: 0.6208 Acc: 0.8142\nEpoch 23/34\n----------\ntrain Loss: 0.6111 Acc: 0.8069\nEpoch 24/34\n----------\ntrain Loss: 0.6377 Acc: 0.8085\nEpoch 25/34\n----------\ntrain Loss: 0.6138 Acc: 0.8061\nEpoch 26/34\n----------\ntrain Loss: 0.6041 Acc: 0.8167\nEpoch 27/34\n----------\ntrain Loss: 0.6267 Acc: 0.8077\nEpoch 28/34\n----------\ntrain Loss: 0.6263 Acc: 0.8052\nEpoch 29/34\n----------\ntrain Loss: 0.6252 Acc: 0.8110\nEpoch 30/34\n----------\ntrain Loss: 0.6315 Acc: 0.8241\nBest val Acc: 0.8241\nEpoch 31/34\n----------\ntrain Loss: 0.6550 Acc: 0.7921\nEpoch 32/34\n----------\ntrain Loss: 0.6245 Acc: 0.8208\nEpoch 33/34\n----------\ntrain Loss: 0.6444 Acc: 0.7889\nEpoch 34/34\n----------\ntrain Loss: 0.6410 Acc: 0.7962\nFinished Training. Best val Acc: 0.8241\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"save_model(efficient_net_model_ft, path='soil_classification_model_efficient_net.pth')\nsave_model(efficient_net_model_base, path='soil_classification_model_efficient_net_base.pth')\nsave_model(v1_model_ft, path='soil_classification_model_v1.pth')\nsave_model(v1_model_base, path='soil_classification_model_v1_base.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:41:40.448633Z","iopub.execute_input":"2025-05-24T11:41:40.449375Z","iopub.status.idle":"2025-05-24T11:41:40.723988Z","shell.execute_reply.started":"2025-05-24T11:41:40.449350Z","shell.execute_reply":"2025-05-24T11:41:40.723273Z"}},"outputs":[{"name":"stdout","text":"Model saved to soil_classification_model_efficient_net.pth\nModel saved to soil_classification_model_efficient_net_base.pth\nModel saved to soil_classification_model_v1.pth\nModel saved to soil_classification_model_v1_base.pth\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# 5. Model Evaluation on Test Set\n# ================================\ndef evaluate_model(model1, model2, model3, model4, dataloader):\n    \"\"\"Evaluates the trained model on the test dataset.\n\n    Args:\n        model (torch.nn.Module): The trained model.\n        dataloader (torch.utils.data.DataLoader): The DataLoader for the test set.\n    \"\"\"\n    model1.eval()\n    model2.eval()\n    model3.eval()# Set the model to evaluation mode\n    running_loss = 0.0\n    running_corrects = 0\n    all_preds = []\n    image_ids = []\n\n    # Iterate over the test data\n    with torch.no_grad():  # Disable gradient calculation for evaluation\n        for inputs, labels in dataloader:\n            inputs = inputs.to(device)\n            #labels = labels.to(device)\n\n            outputs1 = model1(inputs)\n            outputs2 = model2(inputs)\n            outputs3 = model3(inputs)\n            outputs4 = model4(inputs)\n            _, preds1 = torch.max(outputs1, 1)\n            _, preds2 = torch.max(outputs2, 1)\n            _, preds3 = torch.max(outputs3, 1)\n            _, preds4 = torch.max(outputs4, 1)\n            stacked_predictions = torch.stack([preds1.squeeze(), preds2.squeeze(), preds3.squeeze(), preds4.squeeze()])\n            # Find the mode along the first dimension (the models dimension)\n            preds, _ = torch.mode(stacked_predictions, dim=0)\n            image_ids.extend(labels)\n            all_preds.extend(preds.cpu().numpy())\n            #print(len(all_preds))# Store predictions and labels for later analysis\n\n    return all_preds, image_ids  # Return the predictions and labels\n\n# Evaluate the model on the test set\ntest_preds_test, test_image_ids = evaluate_model(efficient_net_model_ft, efficient_net_model_base, v1_model_ft,v1_model_base, dataloaders['test'])\ntest_preds_train, train_image_ids = evaluate_model(efficient_net_model_ft, efficient_net_model_base, v1_model_ft, v1_model_base, dataloaders['train'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:42:04.718193Z","iopub.execute_input":"2025-05-24T11:42:04.718883Z","iopub.status.idle":"2025-05-24T11:42:16.878046Z","shell.execute_reply.started":"2025-05-24T11:42:04.718858Z","shell.execute_reply":"2025-05-24T11:42:16.877059Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def find_keys_for_values(my_dict, value_list):\n    \"\"\"\n    Finds keys in a dictionary corresponding to a list of values, \n    preserving the order of values.\n\n    Args:\n        my_dict (dict): The dictionary to search.\n        value_list (list): A list of values to find keys for.\n\n    Returns:\n        list: A list of keys corresponding to the values in value_list, \n              in the same order. If a value is not found, it's skipped.\n    \"\"\"\n\n    key_list = []\n    for value in value_list:\n        for key, val in my_dict.items():\n            if val == value:\n                key_list.append(key)\n                break  # Move to the next value after finding a key\n    return key_list\n    \n\ntest_image_labels = find_keys_for_values(image_datasets[\"test\"].class_to_idx,  test_preds_test) \nsubmission_df = pd.DataFrame({\"image_id\": test_image_ids, \"soil_type\": test_image_labels})\nsubmission_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:42:26.016055Z","iopub.execute_input":"2025-05-24T11:42:26.016377Z","iopub.status.idle":"2025-05-24T11:42:26.039592Z","shell.execute_reply.started":"2025-05-24T11:42:26.016349Z","shell.execute_reply":"2025-05-24T11:42:26.039030Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"           image_id   soil_type\n0  img_0f035b97.jpg   Clay soil\n1  img_f13af256.jpg  Black Soil\n2  img_15b41dbc.jpg  Black Soil\n3  img_cfb4fc7a.jpg  Black Soil\n4  img_683111fb.jpg  Black Soil","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>soil_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>img_0f035b97.jpg</td>\n      <td>Clay soil</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>img_f13af256.jpg</td>\n      <td>Black Soil</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>img_15b41dbc.jpg</td>\n      <td>Black Soil</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>img_cfb4fc7a.jpg</td>\n      <td>Black Soil</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>img_683111fb.jpg</td>\n      <td>Black Soil</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"submission_df.to_csv(\"submission.csv\")\nsubmission_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:42:30.102525Z","iopub.execute_input":"2025-05-24T11:42:30.102904Z","iopub.status.idle":"2025-05-24T11:42:30.117194Z","shell.execute_reply.started":"2025-05-24T11:42:30.102873Z","shell.execute_reply":"2025-05-24T11:42:30.116552Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"           image_id   soil_type\n0  img_0f035b97.jpg   Clay soil\n1  img_f13af256.jpg  Black Soil\n2  img_15b41dbc.jpg  Black Soil\n3  img_cfb4fc7a.jpg  Black Soil\n4  img_683111fb.jpg  Black Soil","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>soil_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>img_0f035b97.jpg</td>\n      <td>Clay soil</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>img_f13af256.jpg</td>\n      <td>Black Soil</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>img_15b41dbc.jpg</td>\n      <td>Black Soil</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>img_cfb4fc7a.jpg</td>\n      <td>Black Soil</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>img_683111fb.jpg</td>\n      <td>Black Soil</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"test_preds_test\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T18:09:20.979601Z","iopub.status.idle":"2025-05-23T18:09:20.979893Z","shell.execute_reply.started":"2025-05-23T18:09:20.979724Z","shell.execute_reply":"2025-05-23T18:09:20.979740Z"}},"outputs":[],"execution_count":null}]}